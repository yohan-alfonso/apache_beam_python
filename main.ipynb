{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache bean solution for data exploring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creado por: Yohan Alfonso Hernandez\n",
    "### Fecha: 26-05-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lest explore a clean data using the file \"Clean_df\" used in the project 'https://github.com/yohan-alfonso/Exploracion_Datos' the diference is thta in this project we are not gointo to plot just make reading and transforming since the propouse is to practice a little bit of Beam proraming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part we are goin to create the reading and transformations of the dataset\n",
    "- We are goin to sent the out put to a file or you can print it, if you are going to pirnt the resulta you have to uncomment the line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class split_and_lowercase(beam.DoFn):\n",
    "    def process(self, df):\n",
    "        # Split the element into individual words\n",
    "        words = df.split(',')\n",
    "        # Convert each word to lowercase\n",
    "        lowercased_words = [word.lower() for word in words]\n",
    "        # Return the lowercase words as a list\n",
    "        return [lowercased_words]\n",
    "    \n",
    "class filter_mean_salary(beam.DoFn):\n",
    "    def process(self, column):\n",
    "        column_value = column[3]\n",
    "        if column_value != '0.0':\n",
    "            return [column]\n",
    "    \n",
    "\n",
    "\n",
    "def run_pipeline(input_files, output_file):\n",
    "    # Create the Pipeline object\n",
    "    with beam.Pipeline() as pipeline:\n",
    "        # Read the input files into a PCollection\n",
    "        lines = pipeline | \"ReadFiles\" >> ReadFromText(input_files)\n",
    "        \n",
    "         # Split each line by commas\n",
    "         # Split each line into words and convert to lowercase\n",
    "        lowercased_words = lines | \"SplitAndLowercase\" >> beam.ParDo(split_and_lowercase())\n",
    "        \n",
    "        # filter column mean salary diferent from the string '0.0'\n",
    "        filter_mean_sal = lowercased_words | \"filter column\" >> beam.ParDo(filter_mean_salary()) \n",
    "        \n",
    "        # Write the split and filtered lines to the output file\n",
    "        split_and_filtered_lines = filter_mean_sal | \"WriteToFile\" >> WriteToText(output_file, file_name_suffix='.csv')\n",
    "     \n",
    "        #split_and_filtered_lines | beam.Map(print)\n",
    "\n",
    "# Specify the input and output files\n",
    "input_files = 'clean_df.csv'\n",
    "output_file = 'clean_df_filterd'\n",
    "\n",
    "# Run the pipeline\n",
    "run_pipeline(input_files, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv-beam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
